<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>collatz-m4m6 パフォーマンス分析レポート</title>
<style>
  body {
    font-family: "Noto Sans JP", "Hiragino Kaku Gothic ProN", "Yu Gothic", sans-serif;
    max-width: 960px;
    margin: 0 auto;
    padding: 2rem;
    line-height: 1.8;
    color: #222;
    background: #fafafa;
  }
  h1 {
    font-size: 1.6rem;
    border-bottom: 3px solid #333;
    padding-bottom: 0.5rem;
    margin-top: 2rem;
  }
  h2 {
    font-size: 1.3rem;
    border-left: 4px solid #4a7c59;
    padding-left: 0.8rem;
    margin-top: 2.5rem;
  }
  h3 {
    font-size: 1.1rem;
    color: #4a7c59;
    margin-top: 2rem;
  }
  table {
    border-collapse: collapse;
    width: 100%;
    margin: 1.2rem 0;
    font-size: 0.92rem;
  }
  th, td {
    border: 1px solid #ccc;
    padding: 0.5rem 0.8rem;
    text-align: left;
  }
  th {
    background: #e8efe8;
    font-weight: 600;
  }
  td.num {
    text-align: right;
    font-family: "Consolas", "Source Code Pro", monospace;
  }
  .meta {
    color: #666;
    font-size: 0.9rem;
    margin-bottom: 2rem;
  }
  code {
    font-family: "Consolas", "Source Code Pro", monospace;
    background: #eee;
    padding: 0.1rem 0.3rem;
    border-radius: 3px;
    font-size: 0.9em;
  }
  .highlight {
    background: #ffffcc;
    padding: 0.1rem 0.3rem;
  }
  .box {
    background: #f0f5f0;
    border: 1px solid #c5d5c5;
    border-radius: 6px;
    padding: 1rem 1.5rem;
    margin: 1.2rem 0;
  }
  .box-warn {
    background: #fff8f0;
    border: 1px solid #e0c8a0;
  }
  .gpk-stat {
    font-family: "Consolas", "Source Code Pro", monospace;
    font-size: 0.95rem;
    line-height: 2;
  }
  footer {
    margin-top: 3rem;
    padding-top: 1rem;
    border-top: 1px solid #ccc;
    color: #888;
    font-size: 0.85rem;
  }
</style>
</head>
<body>

<h1>collatz-m4m6 パフォーマンス分析レポート</h1>
<p class="meta">
  ペア述語分解スキャンと u128 直接演算の速度差の構造的分析<br>
  2026-02-08 &nbsp;|&nbsp; v0.2.0 &nbsp;|&nbsp; Rust (edition 2021)
</p>

<!-- ========== セクション1 ========== -->
<h2>1. 要旨</h2>
<p>
  collatz-m4m6 は、コラッツ型写像 T(n) = (xn+1)/2<sup>d</sup> の
  m4/m6 ペア述語分解に基づく解析ツールである。
  v0.2.0 では <code>Vec&lt;u64&gt;</code> パックドビット表現と
  Kogge-Stone 並列プリフィックススキャンを導入し、
  v0.1 初期の逐次走査から大幅な構造改善を達成した。
</p>
<p>
  しかし、区間検証（sweep）における実測速度では、
  u128 直接演算の<strong>約4.4億 nums/s</strong> に対し、
  ペアscan経由の処理は数桁遅い結果となった。
  本レポートではこの速度差の構造的原因を分析し、
  ペア述語分解の計算論的意義と今後の展望を述べる。
</p>

<!-- ========== セクション2 ========== -->
<h2>2. 実測ベンチマーク</h2>

<h3>2.1 3n+1 区間検証 (50M奇数, n &le; 99,999,999, max_steps=1000)</h3>
<p>
  Intel Core i7-12650H (Alder Lake, 10C/16T), 64GB DDR5 環境。
  Phase1（u128 直接演算）の ON/OFF と GPK 統計収集の ON/OFF の4条件で計測。
</p>
<table>
  <tr><th>条件</th><th>経過時間</th><th>速度 (nums/s)</th><th>GPK</th><th>Phase1</th></tr>
  <tr><td>u128 のみ</td><td class="num">0.113s</td><td class="num">~442,000,000</td><td>OFF</td><td>ON</td></tr>
  <tr><td>u128 + GPK統計</td><td class="num">2.243s</td><td class="num">~22,300,000</td><td>ON</td><td>ON</td></tr>
  <tr><td>Packed のみ</td><td class="num">9.516s</td><td class="num">~5,250,000</td><td>OFF</td><td>OFF</td></tr>
  <tr><td>Packed + GPK統計</td><td class="num">12.546s</td><td class="num">~3,990,000</td><td>ON</td><td>OFF</td></tr>
</table>
<p>
  u128 のみ（0.113s）と Packed のみ（9.516s）の速度差は約84倍。
  3n+1 ではほぼ全数が u128 Phase 1 で完結するため、この差がそのまま出る。
  GPK 統計の ON/OFF による差は u128 で約20倍。
</p>

<h3>2.2 5n+1 区間検証 (50K奇数, n &le; 99,999, max_steps=1000)</h3>
<p>
  5n+1 は発散系列を含むため、停止時間に到達しない数が存在する。同じ4条件で計測。
</p>
<table>
  <tr><th>条件</th><th>経過時間</th><th>速度 (nums/s)</th><th>GPK</th><th>Phase1</th></tr>
  <tr><td>u128 のみ</td><td class="num">1.667s</td><td class="num">~30,000</td><td>OFF</td><td>ON</td></tr>
  <tr><td>u128 + GPK統計</td><td class="num">3.555s</td><td class="num">~14,100</td><td>ON</td><td>ON</td></tr>
  <tr><td>Packed のみ</td><td class="num">2.118s</td><td class="num">~23,600</td><td>OFF</td><td>OFF</td></tr>
  <tr><td>Packed + GPK統計</td><td class="num">3.995s</td><td class="num">~12,500</td><td>ON</td><td>OFF</td></tr>
</table>
<p>
  5n+1 では発散によりビット長が増大し u128 をオーバーフローするため、
  Phase 1 の恩恵が限定的となる。
  u128 のみ（1.667s）と Packed のみ（2.118s）の差は1.27倍に縮小。
</p>

<h3>2.3 単一ステップ命令数の比較</h3>
<p>
  1ステップあたりの命令数を128bit幅で正規化した比較を示す。
</p>
<table>
  <tr><th>処理</th><th>命令数 / 128bit</th><th>メモリアクセス</th><th>分岐</th></tr>
  <tr><td>u128 (MUL+ADD+TZCNT+SHR)</td><td class="num">4</td><td>なし（レジスタ完結）</td><td>なし</td></tr>
  <tr><td>BigUint (多倍長乗算)</td><td class="num">~6</td><td>Vec&lt;u64&gt; ヒープ</td><td>ループ制御</td></tr>
  <tr><td>Packed scan (Kogge-Stone)</td><td class="num">~25</td><td>Vec&lt;u64&gt; &times;2 ヒープ</td><td>ワードループ</td></tr>
</table>

<!-- ========== セクション3 ========== -->
<h2>3. u128 が圧倒的に速い構造的理由</h2>

<h3>3.1 ハードウェア乗算器の壁</h3>
<p>
  u128 の演算は CPU の乗算器回路で直接実行される。
  Intel Alder Lake の整数乗算パイプラインは 64bit&times;64bit を 3&ndash;4 クロックサイクルで完了し、
  128bit 結果をレジスタペアに格納する。
  この処理にはメモリアクセスが一切発生せず、パイプラインを止める分岐もない。
</p>
<p>
  これは数十億ドル規模の半導体設計投資が生んだハードウェア最適化であり、
  ソフトウェアで組んだビット演算が同じ土俵で競うことは原理的に不可能である。
</p>

<h3>3.2 コラッツ写像の特殊性: 大数 &times; 小定数</h3>
<p>
  コラッツ型写像は T(n) = (xn+1)/2<sup>d</sup> であり、
  x は 3, 5, 9 等の小さな定数である。
  これは「大きな整数 &times; 小さな定数」という乗算パターンに該当し、
  多倍長乗算の中でも最も単純なケースとなる。
  BigUint &times; 定数は各 limb に対して MUL + ADC の2命令で済み、O(n) で完了する。
  ペアscan も O(n) であるため、漸近的計算量は同一だが、定数倍で BigUint が常に有利となる。
</p>

<h3>3.3 sweep の実態: ほぼ全数が u128 内で完結</h3>
<p>
  3n+1 の区間検証では、u64 範囲の入力の大多数が平均3&ndash;5ステップで初期値を下回り、
  停止時間に到達する。この間、値は u128（128bit）を超えることがほとんどなく、
  ペアscan（Phase 2）に遷移する数は極めて少ない。
  つまり sweep を速くするということは u128 ループを速くするということであり、
  packed scan の改善は sweep 速度にほぼ寄与しない。
</p>

<!-- ========== セクション4 ========== -->
<h2>4. 最適化の経緯</h2>
<p>
  v0.1 から v0.2 にかけて、ペアscan 自体は大幅に改善されている。
  しかしそれは sweep 速度の改善ではなく、構造解析の効率化としての改善である。
</p>
<table>
  <tr><th>版</th><th>内部表現</th><th>キャリー解決</th><th>改善</th></tr>
  <tr><td>v0.1 初期</td><td>Vec&lt;u8&gt; per bit</td><td>1ビットずつ逐次</td><td>ベースライン</td></tr>
  <tr><td>v0.1 高速パス</td><td>u128 + BigUint</td><td>CPU乗算器</td><td>sweep 実用化</td></tr>
  <tr><td>v0.2 現行</td><td>Vec&lt;u64&gt; (64ペア/ワード)</td><td>Kogge-Stone (6段)</td><td>メモリ8倍改善</td></tr>
</table>
<p>
  パックド化により、メモリ効率は8倍、ワード内キャリー解決は約10倍に改善された。
  しかし sweep のホットパスは u128 Phase 1 であり、
  これらの改善は Phase 2 到達時にのみ効果を発揮する。
</p>

<h3>4.1 GPK 統計収集の最適化</h3>
<p>
  GPK ON/OFF の切替機構を導入し、統計不要時は
  <code>Vec&lt;u64&gt;</code> 確保・ストア・popcount・max_carry_chain ループを全スキップする設計とした。
  これにより GPK OFF 時の 3n+1 sweep は u128 演算のみとなり、442M nums/s を達成した。
  一方 GPK ON 時は <code>accumulate_gpk_u128</code> のビット逐次ループがボトルネックとなり
  22M nums/s に低下する。
  この約20倍の差が示すのは、GPK 統計収集コスト自体が演算本体より圧倒的に重いという事実である。
</p>

<!-- ========== セクション5 ========== -->
<h2>5. クロスオーバーポイントの分析</h2>
<p>
  ペア述語分解は乗算を使わないため、漸近的計算量において構造的優位性を持つ。
  ビット幅が十分に大きくなると、直接乗算の超線形コストに対して
  ペアscan の線形コストが優位になるクロスオーバーが理論的に存在する。
</p>
<table>
  <tr><th>ビット幅</th><th>直接乗算</th><th>ペアscan</th><th>備考</th></tr>
  <tr><td>~128</td><td>ネイティブ MUL O(1)</td><td>ビット演算 ~30命令</td><td>u128圧勝</td></tr>
  <tr><td>~256</td><td>多倍長 MUL 4回+加算</td><td>Kogge-Stone 1ワード</td><td>BigUint有利</td></tr>
  <tr><td>~1,000</td><td>Karatsuba O(n<sup>1.58</sup>)</td><td>O(n)</td><td>漸近的にペア有利</td></tr>
  <tr><td>~10,000+</td><td>FFT O(n log n)</td><td>O(n), 定数小</td><td>ペアscan優位</td></tr>
</table>

<div class="box box-warn">
<p>
  <strong>補足:</strong>
  コラッツ型写像は「大数 &times; 小定数」であり、BigUint &times; 定数も O(n) で完了する。
  したがって、一般的な多倍長乗算のクロスオーバー表とは異なり、
  定数 &times; n の乗算に限定すれば漸近的計算量は同一（ともに O(n)）となる。
  実測では 32,768bit でも BigUint が約100倍速く、
  コラッツ写像の文脈での速度クロスオーバーは実用的に到達しない。
</p>
</div>

<!-- ========== セクション6 ========== -->
<h2>6. ペア述語分解の本質的価値</h2>

<h3>6.1 構造の可視化: 2<sup>33</sup> 規模検証の GPK 統計</h3>
<p>
  ペア述語分解は、コラッツ写像の1ステップを乗算ではなく
  加算器のキャリー伝播として透明に分解する。
  その副産物である GPK 分類（Generate/Propagate/Kill）は、
  キャリーの生成・伝播・消滅を各ペア位置で定量化し、
  数値の成長/縮小メカニズムを統計的に観測可能にする。
</p>
<p>
  3n+1 写像について、3 から 9,999,999,999（&asymp; 2<sup>33</sup>）の全奇数
  49.9億個を検証した結果から得られた GPK 統計を示す。
</p>

<div class="box">
<p class="gpk-stat">
  G（キャリー生成）= 113,183,623,064 &ensp;(<strong>38.16%</strong>)<br>
  P（キャリー伝播）= &ensp;81,071,432,343 &ensp;(<strong>27.34%</strong>)<br>
  K（キャリー消滅）= 102,328,662,110 &ensp;(<strong>34.50%</strong>)<br>
  総ペア数 &emsp;&emsp;&emsp;&ensp;= 296,583,717,517<br>
  総ステップ数 &emsp;&ensp;= &ensp;17,463,252,353<br>
  全数収束（最大停止時間 282, n = 2,788,008,987）
</p>
</div>

<p><strong>キャリーチェーン長の分布:</strong></p>
<table>
  <tr><th>チェーン長</th><th>出現回数</th><th>チェーン長</th><th>出現回数</th></tr>
  <tr><td class="num">1</td><td class="num">265,878,320</td><td class="num">14</td><td class="num">38,274,610</td></tr>
  <tr><td class="num">2</td><td class="num">1,842,752,124</td><td class="num">15</td><td class="num">22,412,468</td></tr>
  <tr><td class="num">3</td><td class="num">3,494,167,747</td><td class="num">16</td><td class="num">12,790,339</td></tr>
  <tr><td class="num">4</td><td class="num">3,634,880,654</td><td class="num">17</td><td class="num">12,412,547</td></tr>
  <tr><td class="num">5</td><td class="num">2,871,874,977</td><td class="num">18</td><td class="num">2,519,910</td></tr>
  <tr><td class="num">6</td><td class="num">1,991,272,449</td><td class="num">19</td><td class="num">415,078</td></tr>
  <tr><td class="num">7</td><td class="num">1,293,719,531</td><td class="num">20</td><td class="num">69,568</td></tr>
  <tr><td class="num">8</td><td class="num">814,361,343</td><td class="num">21</td><td class="num">11,275</td></tr>
  <tr><td class="num">9</td><td class="num">501,167,658</td><td class="num">22</td><td class="num">1,579</td></tr>
  <tr><td class="num">10</td><td class="num">304,639,101</td><td class="num">23</td><td class="num">337</td></tr>
  <tr><td class="num">11</td><td class="num">183,966,569</td><td class="num">24</td><td class="num">32</td></tr>
  <tr><td class="num">12</td><td class="num">110,232,559</td><td class="num">25</td><td class="num">6</td></tr>
  <tr><td class="num">13</td><td class="num">65,431,568</td><td class="num">26</td><td class="num">4</td></tr>
</table>
<p>
  G% &gt; K% であるにもかかわらず全数が収束するのは、
  G が1ビット高々1の寄与であるのに対し、
  d（2<sup>d</sup> での除算）が平均的に G の効果を上回るためである。
  キャリーチェーン長の分布は 4&ndash;5 にピークを持ち、最大は 26 である。
  これは、キャリー伝播が局所的に留まり、
  長距離伝播が指数的に稀であることを示す。
</p>
<p>
  この知見 &mdash; キャリーの局所性、G/K 比率の安定性、チェーン長の幾何分布 &mdash; は
  乗算ベースのアプローチからは直接得られない構造情報であり、
  ペア述語分解の固有の価値である。
</p>

<h3>6.2 回路化ポテンシャル</h3>
<p>
  Kogge-Stone アルゴリズムは元来ハードウェア加算器の設計手法であり、
  ペア述語分解を FPGA/ASIC で実装すれば、
  乗算器を経由せずにコラッツ写像の1ステップを加算器の深さ O(log n) で完了できる。
  固定幅に制約されない点も利点であり、回路設計上の自然な拡張性を持つ。
</p>
<p>
  ただし、本論文の主張は「最速のコラッツ計算の実現」ではない。
  回路化は本手法が加算器構造に直接写像されるという理論的整合性の一例として示すものであり、
  ペア述語分解の計算論的意義をパフォーマンス比較に帰結させるものではない。
</p>

<h3>6.3 GPK 統計収集における実質的優位性</h3>
<p>
  ペア述語分解の実用上の明確な利点は、GPK 統計の取得コストにある。
  実測ベンチマーク（セクション2）から、GPK 統計収集の有無による速度差を比較する。
</p>
<table>
  <tr><th></th><th>GPK OFF</th><th>GPK ON</th><th>GPK オーバーヘッド</th></tr>
  <tr><td>u128 演算</td><td class="num">442M nums/s</td><td class="num">22M nums/s</td><td><span class="highlight">約20倍低下</span></td></tr>
  <tr><td>Packed scan</td><td class="num">5.25M nums/s</td><td class="num">3.99M nums/s</td><td>約1.3倍低下</td></tr>
</table>
<p>
  u128 直接演算では、GPK 統計を取得するために乗算とは別のパスで
  ビット分解を行う必要があり、これが約20倍の速度低下を引き起こす。
  一方、ペアscan では GPK はスキャン過程の副産物として自然に得られるため、
  追加コストは1.3倍に留まる。
</p>
<p>
  GPK 統計が必要な場面（すなわち本論文の分類検証）での実質的な比較は：
</p>
<div class="box">
<p>
  u128 + GPK: &ensp;<strong>22M nums/s</strong><br>
  Packed + GPK: <strong>4M nums/s</strong><br>
  速度差: <strong>約5.5倍</strong>（GPK 不要時の84倍から大幅に縮小）
</p>
</div>
<p>
  ペアscan は「遅いが構造が見える」のではなく、
  <strong>「構造を見るならば計算速度をほぼ欠損しない」</strong>手法である。
</p>
<p>
  論文が示すのは写像の構造的性質であり、ソフトウェアベンチマークの勝敗ではない。
  ペア述語分解は、コラッツ写像を加算器のキャリー伝播として透明に分解し、
  GPK 統計という定量的解析手段を演算の副産物として提供する。
  これが本ツールの存在意義であり、分類論文の検証基盤としての価値である。
</p>

<!-- ========== セクション7 ========== -->
<h2>7. 今後の展望</h2>
<p>
  ペアscan の速度改善と、ペア述語分解の構造的価値を活用する方向の両面で展望を整理する。
</p>
<table>
  <tr><th>アプローチ</th><th>概要</th><th>期待効果</th><th>適用領域</th></tr>
  <tr><td>SIMD (AVX2/512)</td><td>256/512bit幅で複数ワード同時処理</td><td>理論4-8倍</td><td>packed scan本体</td></tr>
  <tr><td>ワード間並列化</td><td>Kogge-Stoneをワード間にも適用</td><td>大数で有効</td><td>1000bit以上</td></tr>
  <tr><td>篩（ふるい）</td><td>GPK分類で収束確定の剰余類をスキップ</td><td>数学的削減</td><td>sweep全体</td></tr>
  <tr><td>SIMD複数数並列</td><td>AVX2で4つのu64数を同時走査</td><td>理論4倍</td><td>sweep (u64範囲)</td></tr>
  <tr><td>FPGA/ASIC回路化</td><td>ペア述語分解を加算器回路として実装</td><td>1クロック/ステップ</td><td>理論的整合性の実証</td></tr>
</table>

<h3>7.1 sweep 高速化の最有力候補: 篩（ふるい）</h3>
<p>
  GPK 分類に基づく剰余類解析により、
  「この剰余類は必ず K 優勢 &rarr; 収束確定」という定理が導出できれば、
  数学的にスキップ可能な数を事前に除外できる。
  これはペア述語分解が速度にも直接貢献する唯一の経路であり、
  ツールの存在意義を最も強く正当化する方向性である。
</p>

<h3>7.2 SIMD による packed scan 高速化</h3>
<p>
  AVX2 (256bit) では4ワード、AVX-512 (512bit) では8ワードを同時処理でき、
  Kogge-Stone のワード内演算を SIMD 化すれば理論的に4&ndash;8倍の改善が見込める。
  ただし sweep のホットパスが u128 である限り、
  packed scan の高速化は大きい数のトレース用途に限定される。
</p>

<h3>7.3 ワード間キャリーの並列化</h3>
<p>
  現在の実装ではワード間キャリーは逐次伝播
  （<code>carry_out = carry_after &gt;&gt; 63</code> &rarr; 次ワードへ）である。
  ワード間にも Kogge-Stone を適用すれば、k ワードのキャリー解決が O(log k) に改善される。
  1000bit 以上の大きい数で有効だが、sweep の u64 入力範囲には影響しない。
</p>

<h3>7.4 FPGA 実装</h3>
<p>
  ペア述語分解を FPGA 上の加算器回路として実装し、
  乗算器なしでの1クロック/ステップ動作を実証することが、
  本手法の回路的整合性の検証となる。
  Kogge-Stone プリフィックスツリーを並列に配置し、
  参照パターンの配線を固定すれば、
  任意幅のコラッツステップが加算器の段数（O(log n)）で完了する回路を構成できる。
</p>

<!-- ========== セクション8 ========== -->
<h2>8. 結論</h2>
<p>
  collatz-m4m6 v0.2.0 の実測速度は u128 直接演算に対して数桁劣る。
  しかしこの差は「CPU 乗算器ハードウェア vs ソフトウェアビット演算」という
  非対称な比較の結果であり、ペア述語分解のアルゴリズム的価値を否定するものではない。
</p>
<p>
  ペア述語分解が提供するのは、コラッツ写像を加算器のキャリー伝播として透明に分解し、
  GPK 統計という定量的解析手段を与えることである。
  GPK 統計が必要な場面では、ペアscan のオーバーヘッドは1.3倍に留まり、
  u128 演算の20倍のオーバーヘッドに対して実質的な優位性を持つ。
</p>
<p>
  述語体系の話と速度は独立である。
  本ツールの価値は、コラッツ写像の構造を可視化し、
  分類論文の検証基盤を提供する点にある。
  速度はその手段であって目的ではない。
</p>

<footer>
  collatz-m4m6 v0.2.0 &nbsp;|&nbsp; Rust edition 2021 &nbsp;|&nbsp;
  Intel Core i7-12650H, 64GB DDR5 &nbsp;|&nbsp; 2026-02-08
</footer>

</body>
</html>
